# Spatial-CLIP


## Install

1. Clone this repository and navigate to LLaVA folder
```bash
git clone https://github.com/master-chou/spatial-clip.git
cd spatial-clip
```

2. Install Package
```Shell
conda create -n spclip python=3.10 -y
conda activate spclip
pip install --upgrade pip  # enable PEP 660 support
pip install -r requirements.txt
```

This project builds upon and extends the work from [LLaVA](https://github.com/haotian-liu/LLaVA) and [AlphaCLIP](https://github.com/microsoft/AlphaCLIP), incorporating spatial understanding capabilities into vision-language models.

## Acknowledgments

This repository is built upon the following excellent open-source projects:

### LLaVA
- **Repository**: [https://github.com/haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA)
- **Paper**: [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485)
- **License**: Apache License 2.0

### AlphaCLIP
- **Repository**: [https://github.com/microsoft/AlphaCLIP](https://github.com/microsoft/AlphaCLIP)
- **Paper**: [AlphaCLIP: A CLIP Model Focusing on Wherever You Want](https://arxiv.org/abs/2312.03818)
- **License**: MIT License

## Citations

If you find this project useful, please consider citing our work along with the original papers:

Coming soon.
